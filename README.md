# Thousand Facial Landmarks Competition

Репозиторий содержит код решения Kaggle InClass соревнования [Thousand Facial Landmarks Competition](https://www.kaggle.com/c/made-thousand-facial-landmarks), проходившего в рамках курса по компьютерному зрению в [Академии больших данных MADE](https://data.mail.ru).

Необходимо было предсказать координаты x и y для 971-ой точки лица. Обучающая выборка состоит из 393'930 изображений, тестовая – из 99'819 изображений. Метрика – MSE с усреднением по всем объектам. Для сабмита для каждой фотографии в test_points.csv задано 30 индексов точек (из диапазона от 0 до 970), которые необходимо предоставить. Только эти 30 точек (x, y) (60 значений) используются для вычисления MSE на одном объекте на Public и Private Leaderboard.


### В рамках задачи:
* Эксперименты проводились в research.ipynb на Google Colab. Основной датасет (data/) загружался в виде [zip-архива с Kaggle Datasets](https://www.kaggle.com/nikolaygurev/made-thousand-facial-landmarks-data) (примерно 13.5 Гб).
* Размеченная выборка (data/train/) была случайным образом разбита на обучающую и валидационную в соотношении 80 % на 20 %. Индексы зафиксированы в utils/train_indices.txt и utils/val_indices.txt. Разбиение реализовано в utils/train_val_indices_generation.ipynb.
* Обучение каждой модели происходило 40 эпох (иногда меньше, если результат был понятен раньше). В каждой эпохе модель обучалась по батчам. Качество на валидационной выборке измерялось после каждой эпохи, по нему выбиралось оптимальное число эпох обучения.
* Код для загрузки датасета, обучения моделей и построения прогноза основан на бейзлайне от организаторов.
* Иcпользовался оптимизатор Adam с learning rate = 0.001.
* Опробованы сети семейства resnet: resnet18, resnet34, resnet50, resnet101. Лучшее качество показала сеть resnet101.
* Опробована мобильная сеть mnasnet1_0. Показала самое плохое качество.
* Опробована сеть xception. Показала качество на уровне resnet18.
* Большинство экспериментов проводилось с использованием сети resnet18, 30 % данных из обучающей выборки и 50 % данных из валидационной выборки:
	* Обучение не pretrained сети resnet18. Качество было хуже, чем у pretrained.
	* Обучение pretrained сети resnet18 с заморозкой всех слоёв кроме последнего полносвязного слоя. Качество было значительно хуже, чем при обучение всех слоёв.
	* Подбор размера батча. Лучшее качество было получено при размере батча 64 изображения.
	* Использование learning rate schedulers: StepLR, ReduceLROnPlateau и увеличение стартового learning rate в оптимизаторе Adam. Ускорялась сходимость на первых эпохах, но итоговое качество практически не менялось.
* В utils/local_and_kaggle_scores.ipynb проведена проверка того, что в тестовой выборке все точки используются с одинаковой частотой (т.е. каждая из 971-ой точки равновероятно попадает в список из 30 точек для сабмита).
* Визуализация предсказаний для тестовой выборки производилась в utils/test_predictions_visualization.ipynb.
* Описание моделей и результаты экспериментов залогированы в experiments_logs/experiments_logs.csv (оригинал – experiments_logs/experiments_logs.numbers). Качество моделей по эпохам залогировано в текстовых файлах в experiments_logs/.
* График линейной зависимости между MSE на валидационной выборке и MSE на Public Leaderboard на Kaggle построен в utils/local_and_kaggle_scores.ipynb. Различие в значениях объясняется тем, что на валидационной выборке метрика вычислялась на сжатых обрезанных изображениях.

### Результат:
* Лучшее качество и на валидационной выборке, и на Public Leaderboard показала pretrained сеть resnet101 без замороженных слоёв, которая обучалась 20 эпох на всей обучающей выборке с размером батча 64 изображения без использования learning rate scheduler. Обучение модели в течение большего числа эпох снижало MSE на обучающей выборке, но практически не меняло на валидационной.
* Итог: 22-ое место на Private LB и 26-ое место на Public LB из 85 участников.

![submission_score](readme_images/submission_score.png)
![leaderboard_position](readme_images/leaderboard_position.png)
